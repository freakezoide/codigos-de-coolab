{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4aZWz5/q7txzSSMav2lxd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/freakezoide/codigos-de-coolab/blob/main/limpieza_de_datos_primaria_desde_2019_hasta_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OWOHzs9hAzA",
        "outputId": "95fa76b0-18d7-48ae-81fe-313ad49c364e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: No se encontró el archivo 2019primaria.csv\n",
            "\n",
            "=== REPORTE DE CALIDAD DE DATOS ===\n",
            "Registros totales: 12353\n",
            "\n",
            "Valores faltantes por columna:\n",
            "Año                        0\n",
            "Mes                        0\n",
            "Departamento               0\n",
            "Ciclo                      0\n",
            "Zona                       0\n",
            "Contexto                 710\n",
            "UsuariosCREA               0\n",
            "UsuariosMAT                0\n",
            "UsuariosBiblioteca         0\n",
            "InteraccionCREA            0\n",
            "InteraccionMAT             0\n",
            "InteraccionBiblioteca      0\n",
            "dtype: int64\n",
            "\n",
            "Distribución de interacciones:\n",
            "\n",
            "CREA:\n",
            "InteraccionCREA\n",
            "Baja     36.428398\n",
            "Alta     33.352222\n",
            "Media    30.219380\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "MAT:\n",
            "InteraccionMAT\n",
            "Media    56.957824\n",
            "Baja     35.562212\n",
            "Alta      7.479964\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Biblioteca:\n",
            "InteraccionBiblioteca\n",
            "Baja     77.333441\n",
            "Media    22.666559\n",
            "Alta      0.000000\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Consistencia temporal:\n",
            "Mes   Abril  Agosto  Diciembre  Julio  Junio  Marzo   Mayo  Noviembre  \\\n",
            "Año                                                                     \n",
            "2020  163.0   175.0      211.0  189.0  179.0  156.0  164.0      178.0   \n",
            "2021  168.0   215.0      230.0  223.0  192.0  202.0  154.0      222.0   \n",
            "2022  219.0   178.0      222.0  190.0  182.0  204.0  198.0      216.0   \n",
            "2023  207.0   204.0      438.0  398.0  200.0  378.0  190.0      214.0   \n",
            "2024  411.0   493.0      453.0  504.0    NaN  430.0  182.0      523.0   \n",
            "\n",
            "Mes   Octubre  Setiembre  \n",
            "Año                       \n",
            "2020    174.0      170.0  \n",
            "2021    215.0      243.0  \n",
            "2022    184.0      191.0  \n",
            "2023    398.0      398.0  \n",
            "2024      NaN      525.0  \n",
            "\n",
            "Datos limpios exportados a 'datos_educativos_limpios.csv'\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Limpieza avanzada de datos para análisis de interacción\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## 1. Carga de datos con controles mejorados\n",
        "archivos = [\"2019primaria.csv\", \"2020Primaria.csv\", \"2021 primaria.csv\",\n",
        "            \"2022 primaria.csv\", \"2023 primaria.csv\", \"2024 primaria.csv\"]\n",
        "\n",
        "# Cargar con verificación de archivos\n",
        "dfs = []\n",
        "for archivo in archivos:\n",
        "    try:\n",
        "        df_temp = pd.read_csv(archivo)\n",
        "        # Verificar columnas mínimas requeridas\n",
        "        required_cols = ['UsuariosCREA', 'UsuariosMAT', 'UsuariosBiblioteca', 'Departamento', 'Mes', 'Año']\n",
        "        if all(col in df_temp.columns for col in required_cols):\n",
        "            dfs.append(df_temp)\n",
        "        else:\n",
        "            print(f\"Advertencia: El archivo {archivo} no tiene todas las columnas requeridas\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: No se encontró el archivo {archivo}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar {archivo}: {str(e)}\")\n",
        "\n",
        "if not dfs:\n",
        "    raise ValueError(\"No se pudieron cargar datos válidos de ningún archivo\")\n",
        "\n",
        "df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "## 2. Limpieza avanzada de datos\n",
        "def limpieza_avanzada(df):\n",
        "    # Eliminar duplicados exactos y casi-duplicados\n",
        "    df = df.drop_duplicates()\n",
        "\n",
        "    # Eliminar filas donde todas las métricas de interacción son cero o faltantes\n",
        "    metricas = ['UsuariosCREA', 'UsuariosMAT', 'UsuariosBiblioteca']\n",
        "    df = df.dropna(subset=metricas, how='all')\n",
        "    df = df[~(df[metricas] == 0).all(axis=1)]\n",
        "\n",
        "    # Limpieza de campos categóricos\n",
        "    if 'Departamento' in df.columns:\n",
        "        df['Departamento'] = df['Departamento'].str.strip().str.title()\n",
        "        df['Departamento'] = df['Departamento'].replace({\n",
        "            'Montevideo': 'Montevideo',\n",
        "            'Canelones': 'Canelones',\n",
        "            'Maldonado': 'Maldonado'\n",
        "            # Agregar más estandarizaciones según necesidad\n",
        "        })\n",
        "\n",
        "    # Estandarización de meses\n",
        "    meses_map = {\n",
        "        'Ene': 'Enero', 'Feb': 'Febrero', 'Mar': 'Marzo', 'Abr': 'Abril',\n",
        "        'May': 'Mayo', 'Jun': 'Junio', 'Jul': 'Julio', 'Ago': 'Agosto',\n",
        "        'Set': 'Septiembre', 'Oct': 'Octubre', 'Nov': 'Noviembre', 'Dic': 'Diciembre'\n",
        "    }\n",
        "    df['Mes'] = df['Mes'].str.strip().str.title().replace(meses_map)\n",
        "\n",
        "    # Validación de rangos numéricos\n",
        "    for col in metricas:\n",
        "        df = df[(df[col] >= 0) & (df[col] <= 100)]  # Asumiendo que son porcentajes\n",
        "\n",
        "    # Eliminar outliers usando IQR\n",
        "    for col in metricas:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        df = df[~((df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR)))]\n",
        "\n",
        "    return df\n",
        "\n",
        "df = limpieza_avanzada(df)\n",
        "\n",
        "## 3. Clasificación mejorada de interacciones\n",
        "def clasificar_interaccion_mejorada(serie):\n",
        "    # Usar percentiles robustos (menos sensibles a outliers)\n",
        "    bajo = serie.quantile(0.33)\n",
        "    medio = serie.quantile(0.66)\n",
        "\n",
        "    # Asegurar que los límites sean significativos\n",
        "    if medio - bajo < 5:  # Si la diferencia es muy pequeña\n",
        "        medio = bajo + 10  # Ajuste empírico\n",
        "\n",
        "    return pd.cut(serie,\n",
        "                bins=[-1, bajo, medio, float('inf')],\n",
        "                labels=['Baja', 'Media', 'Alta'],\n",
        "                include_lowest=True)\n",
        "\n",
        "# Aplicar clasificación mejorada\n",
        "df['InteraccionCREA'] = clasificar_interaccion_mejorada(df['UsuariosCREA'])\n",
        "df['InteraccionMAT'] = clasificar_interaccion_mejorada(df['UsuariosMAT'])\n",
        "df['InteraccionBiblioteca'] = clasificar_interaccion_mejorada(df['UsuariosBiblioteca'])\n",
        "\n",
        "## 4. Análisis de calidad de datos\n",
        "def reporte_calidad(df):\n",
        "    print(\"\\n=== REPORTE DE CALIDAD DE DATOS ===\")\n",
        "    print(f\"Registros totales: {len(df)}\")\n",
        "    print(\"\\nValores faltantes por columna:\")\n",
        "    print(df.isnull().sum())\n",
        "    print(\"\\nDistribución de interacciones:\")\n",
        "    for plataforma in ['CREA', 'MAT', 'Biblioteca']:\n",
        "        print(f\"\\n{plataforma}:\")\n",
        "        print(df[f'Interaccion{plataforma}'].value_counts(normalize=True) * 100)\n",
        "\n",
        "    # Verificar consistencia temporal\n",
        "    if 'Año' in df.columns and 'Mes' in df.columns:\n",
        "        print(\"\\nConsistencia temporal:\")\n",
        "        print(df.groupby('Año')['Mes'].value_counts().unstack())\n",
        "\n",
        "reporte_calidad(df)\n",
        "\n",
        "## 5. Exportar datos limpios\n",
        "df.to_csv('datos_educativos_limpios.csv', index=False)\n",
        "print(\"\\nDatos limpios exportados a 'datos_educativos_limpios.csv'\")"
      ]
    }
  ]
}